{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "import requests as r\n",
    "import re\n",
    "import json\n",
    "import csv\n",
    "import sys\n",
    "sys.path.append(\"./scripts\")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import scrapebrew as sb\n",
    "\n",
    "sb.scrape_brewer_friends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "beer_recipes = pd.read_csv(\"./data/brewer_scrape_test_small.csv\", keep_default_na=False)\n",
    "print(beer_recipes.head(5).brewed_count[0])\n",
    "test = beer_recipes.head(5)\n",
    "test.title_url[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_recipes_details(title_url_list):\n",
    "    \"\"\"\n",
    "        scrape_recipes_details maintains the control flow structure that allows for the scraping of \n",
    "        4954 pages of beer recipes. This function looks to extract detailed information for each beer recipe.\n",
    "        Information such as ratings, reviews and view count that will be combined with the orignal set of information\n",
    "        extracted.\n",
    "        Args:\n",
    "            title_url_list (array): An array of title urls that will be use to scrape more details about the \n",
    "            beer recipes.\n",
    "            \n",
    "    \"\"\"\n",
    "    general, reviews = [], []\n",
    "    for i in range(len(title_url_list)):\n",
    "        append_gen, append_reviews = scrape_detail_page(title_url_list[i])\n",
    "        print(\"Completed scraping beer recipes details from: \" + title_url_list[i])\n",
    "        general.append(append_gen)\n",
    "        reviews = reviews + append_reviews\n",
    "    write_detail_recipe_to_csv(general)\n",
    "    print(\"Completed writing detailed beer recipes to CSV\")\n",
    "    write_recipe_reviews_to_csv(reviews)\n",
    "    print(\"Completed writing beer recipes reviews to CSV\")\n",
    "\n",
    "    \n",
    "\n",
    "def write_detail_recipe_to_csv(recipes_list):\n",
    "    \"\"\"\n",
    "        write_detail_recipe_to_csv takes in a recipes_list array and writes the data out into a CSV\n",
    "        Args:\n",
    "            recipe_list (array): An array of beer recipes with fields that were not readily available unless \n",
    "            viewed from a detail beer recipe page.\n",
    "    \"\"\"\n",
    "    with open(\"data/brewer_scrape_detail_test.csv\", mode='w', encoding='utf-8') as csv_file:\n",
    "        field_names = [\"title_url\", \"mash_ph\", \"rating_value\", \"rating_count\", \"view_count\"]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "        writer.writeheader()\n",
    "        for row in recipes_list:\n",
    "            writer.writerow(row)\n",
    "            \n",
    "def write_recipe_reviews_to_csv(reviews_list):\n",
    "    \"\"\"\n",
    "        write_recipe_reviews_to_csv takes in a reviews_list array and writes the data out into a CSV\n",
    "        Args:\n",
    "            reviews_list (array): An array of beer recipes reviews with an assortment of fields.\n",
    "    \"\"\"\n",
    "    with open(\"data/brewer_scrape_reviews_test.csv\", mode='w', encoding='utf-8') as csv_file:\n",
    "        field_names = [\"title_url\", \"reviewer_url\", \"reviewer_name\", \"review_description\",\n",
    "                       \"review_rating\", \"reviewer_date\", \"reviewer_time\"]\n",
    "        writer = csv.DictWriter(csv_file, fieldnames=field_names)\n",
    "        writer.writeheader()\n",
    "        for row in reviews_list:\n",
    "            writer.writerow(row)\n",
    "\n",
    "def scrape_detail_page(page_url):\n",
    "    \"\"\"\n",
    "        scrape_detail_page takes in a page_url string used to extract detail information and reviews for that \n",
    "        particular beer recipe url.\n",
    "        Args:\n",
    "            page_url (string): An string that represents a beer recipe page url\n",
    "        Return:\n",
    "            Returns two arrays. The first contains additional general information about a beer recipe. \n",
    "            The other contains reviews left for that beer recipe.\n",
    "    \"\"\"\n",
    "    page = r.get(page_url, headers={'User-Agent':'Mozilla/5.0'})\n",
    "    soup = bs(page.content, \"html.parser\")\n",
    "    \n",
    "    page_general_details = extract_general_recipe_detail(soup, page_url)\n",
    "    reviews_list = extract_recipe_reviews(soup, page_url)\n",
    "    return page_general_details, reviews_list\n",
    "    \n",
    "    \n",
    "def extract_general_recipe_detail(soup, title_url):\n",
    "    \"\"\"\n",
    "        extract_general_recipe_detail takes in a BeautifulSoup object that represents the HTML makeup of the particular\n",
    "        url (title_url) for a particular beer recipe. This function extracts general information about the beer recipe\n",
    "        used to be combine to an existing data set.\n",
    "        Args:\n",
    "            soup (object): A BeautifulSoup object that represents the HTML makeup of a page.\n",
    "            title_url (string): An string that represents a beer recipe page url\n",
    "        Return:\n",
    "            Returns an object that represents additional general information for a beer recipe\n",
    "    \"\"\"\n",
    "    result = {}\n",
    "    mash_ph = soup.find(\"div\", {\"class\": \"phMin\"}).text.strip()\n",
    "    \n",
    "    result[\"title_url\"] = title_url\n",
    "    \n",
    "    result[\"mash_ph\"] = mash_ph\n",
    "    rating_div = soup.find(\"div\", {\"class\": \"reviews\"})\n",
    "    rating_value = \"N/A\"\n",
    "    rating_count = 0\n",
    "    if (rating_div != None):\n",
    "        rating_value = rating_div.find(\"span\", {\"itemprop\": \"ratingValue\"}).text.strip()\n",
    "        rating_count = rating_div.find(\"span\", {\"itemprop\": \"reviewCount\"}).text.strip()\n",
    "    result[\"rating_value\"] = rating_value\n",
    "    result[\"rating_count\"] = rating_count\n",
    "\n",
    "    view_count_div = soup.find(\"div\", {\"class\": \"lastupdated\"})\n",
    "    view_count_bold = view_count_div.findAll(\"b\")\n",
    "    view_count = view_count_bold[0].text.replace(\"View Count: \", \"\").strip()\n",
    "    result[\"view_count\"] = view_count\n",
    "    \n",
    "    return result\n",
    "\n",
    "    \n",
    "    \n",
    "def extract_recipe_reviews(soup, title_url):\n",
    "    \"\"\"\n",
    "        extract_general_recipe_detail takes in a BeautifulSoup object that represents the HTML makeup of the particular\n",
    "        url (title_url) for a particular beer recipe. This function extracts reviews about the beer recipe\n",
    "        used to be combine to an existing data set.\n",
    "        Args:\n",
    "            soup (object): A BeautifulSoup object that represents the HTML makeup of a page.\n",
    "            title_url (string): An string that represents a beer recipe page url\n",
    "        Return:\n",
    "            Returns an array of review object\n",
    "    \"\"\"\n",
    "    brewpart_divs = soup.findAll(\"div\", {\"class\": \"brewpart\"})\n",
    "    brewpart_review_div = brewpart_divs[len(brewpart_divs) - 1]\n",
    "    brewpart_review_tables = brewpart_review_div.find(\"table\").find(\"td\").findAll(\"table\")\n",
    "    reviews = []\n",
    "    \n",
    "    if (len(brewpart_review_tables) != 0):\n",
    "        for i in range(len(brewpart_review_tables)):\n",
    "            review = {}\n",
    "\n",
    "            review[\"title_url\"] =  title_url\n",
    "\n",
    "            review_tds = brewpart_review_tables[i].findAll(\"td\")\n",
    "            review_td = review_tds[len(review_tds) - 1]\n",
    "\n",
    "            reviewer_url = \"N/A\"\n",
    "            reviewer_name = \"N/A\"\n",
    "            if (review_td.find(\"a\") != None):\n",
    "                reviewer_url = review_td.find(\"a\")[\"href\"]\n",
    "                reviewer_name = review_td.find(\"a\").text\n",
    "            else: \n",
    "                reviewer_name = review_td.find(\"font\").text\n",
    "\n",
    "            review[\"reviewer_url\"] = reviewer_url\n",
    "            review[\"reviewer_name\"] = reviewer_name\n",
    "\n",
    "            review_fonts = review_td.findAll(\"font\")\n",
    "            review_td_datetime = review_fonts[1].text.split(\"at\")\n",
    "            review_date = review_td_datetime[0].replace(\"â€¢\", \"\").strip()\n",
    "            review[\"reviewer_date\"] = review_date\n",
    "\n",
    "            review_time = review_td_datetime[1].strip()\n",
    "            review[\"reviewer_time\"] = review_time\n",
    "\n",
    "            review_description = \"N/A\"\n",
    "            if (review_fonts[len(review_fonts) - 1] != None):  \n",
    "                review_description = review_fonts[len(review_fonts) - 1].text.strip()\n",
    "            review[\"review_description\"] = review_description\n",
    "\n",
    "            review_rating = \"N/A\"\n",
    "            review_rating_span = brewpart_review_tables[i].find(\"span\", {\"class\": \"blue\"})\n",
    "            if (review_rating_span != None):\n",
    "                review_rating = review_rating_span.text.replace(\"of 5\", \"\").strip()\n",
    "            review[\"review_rating\"] = review_rating\n",
    "\n",
    "            reviews.append(review)\n",
    "    return reviews\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed scraping beer recipes details from: https://www.brewersfriend.com/homebrew/recipe/view/28546/sierra-nevada-pale-ale-clone\n",
      "Completed scraping beer recipes details from: https://www.brewersfriend.com/homebrew/recipe/view/363082/avg-perfect-northeast-ipa-neipa-\n",
      "Completed scraping beer recipes details from: https://www.brewersfriend.com/homebrew/recipe/view/5916/zombie-dust-clone-all-grain\n",
      "Completed scraping beer recipes details from: https://www.brewersfriend.com/homebrew/recipe/view/5920/zombie-dust-clone-extract\n",
      "Completed scraping beer recipes details from: https://www.brewersfriend.com/homebrew/recipe/view/16367/southern-tier-pumking-clone\n",
      "Completed writing detailed beer recipes to CSV\n",
      "Completed writing beer recipes reviews to CSV\n"
     ]
    }
   ],
   "source": [
    "beer_recipes = pd.read_csv(\"./data/brewer_scrape_test_small.csv\", keep_default_na=False)\n",
    "testing_data = beer_recipes.head(5)\n",
    "testing_url = testing_data.title_url\n",
    "\n",
    "scrape_recipes_details(testing_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
